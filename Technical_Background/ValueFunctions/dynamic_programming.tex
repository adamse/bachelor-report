\subsection{Dynamic Programming \note{N}}

Dynamic programming is a way of dividing a problem into subproblems that only have to be solved once each. Later, if the result of a particular subproblem is needed again, it can be looked up from a table of previously solved subproblems. In reinforcement learning, dynamic programming can be used to calculate the value functions of an MDP \parencite{bellman1957mdp}. Examples of dynamic programming algorithms are policy iteration and value iteration, which are discussed in section \ref{sec:pol_itr} and \ref{sec:valueiteration}. These algorithms are often the basis for more advanced algorithms, among them the ones described in chapter \ref{ch:algo}, which are the focus of this thesis. 