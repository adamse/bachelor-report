\chapter{Algorithms}
\label{ch:algo}

The main topic of the thesis is to study techniques that can be used for in
reinforcement learning in large state spaces, both algorithms deal with this
issue; however, they differ in the methods they apply. In the following chapter
the general ideas behind the algorithms, as well as specific details, are
presented. 

The model-based interval estimation algorithm, described in
section~\ref{sec:mbie}, utilizes clever estimations of confidence intervals for
the Q-value functions to improve performance in sparse MDPs.
Section~\ref{sec:fac_e3} is on an algorithm that uses dynamic Bayesian networks
and factored representations to improve the \etre\ algorithm to more efficently
deal with factored MDPs. 

<<<<<<< HEAD
\input{Algorithms/mbie.tex}

=======
>>>>>>> 20f5b0ada686c7e68d750ec31c0b150b8197a865
\input{Algorithms/factored_e3.tex}
