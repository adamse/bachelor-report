\chapter{Algorithms}
\label{ch:algo}

The main topic of the thesis is to study techniques that can be used for
reinforcement learning in large state spaces. Both algorithms in this chapter deal with this
issue; however, they differ in the methods they apply. In the following chapter
the general ideas behind the algorithms, as well as specific details, are
presented. 

The model-based interval estimation algorithm, described in
section~\ref{sec:mbie}, utilizes clever estimations of confidence intervals for
the Q-value functions to improve performance in sparse MDPs.
Section~\ref{sec:fac_e3} is on an algorithm that uses dynamic bayesian networks
and factored representations to improve the \etre\ algorithm to more efficiently deal with factored MDPs. 

\input{algorithms/mbie.tex}
\input{algorithms/factored_e3.tex}
