%\subsection{Our contribution}
\subsection{Factored additions to \etre}
\label{sec:factored_e3}

The \etre\ algorithm does not exploit that the underlying Markov Decision
Process may be structured in a way that allows certain optimizations. Therefore
\etre\ has a running time that scales polynomially with the number of states in
the MDP. However, by using a factored approach for the problem, improvements
can be made to the running time. By factoring the problem as a dynamic Bayesian
network, the running time will scale with the number of random variables in the
underlying DBN instead for the number of states
\parencite{kearns1999efficient}. 

When using a factored representation some changes to the original algorithm are
required to make it compatible. One issue that has to be solved is how to
perform  planning with the new representation. In this thesis a modified version
of value iteration was used for planning and it is described later in this
section. In section \ref{sec:better_planing_algos} there are other methods
presented.


\paragraph{Dynamic Bayesian network structure}

Assume that the states of an MDP each are divided into several variables. For
instance, the invasive species MDP described in section
\ref{sec:experiment_env} constitutes such a case, where the status of each
reach can be considered a variable on its own. The number of tamarisk trees,
native trees and empty slots in a certain reach at time step $t+1$ depends not
on the whole state of the environment at time $t$, but only on the status of
adjacent reaches. Those variables on which another variable depend are called
its parents.  

An MDP that follows the description in the previous paragraph is described as
factored. With the assumption of a factored MDP, it is possible to describe its
transition probabilities as a dynamic Bayesian network, where one would have a
small transition probability table for each of the reaches in the MDP, instead
of a large table for the transitions for the whole states.
