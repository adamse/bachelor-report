%\subsection{Our contribution}
\subsection{Factored additions to \etre}
\label{sec:factored_e3}

The \etre\ algorithm does not exploit that the underlying Markov decision
process may be structured in a way that allows certain optimizations. For instance, 
by factoring the problem as a dynamic bayesian
network, the running time can be improved dramatically 
\parencite{kearns1999efficient}. 

When using a factored representation some changes to the original algorithm are
required to make it compatible. One issue that has to be solved is how to
perform  planning with the new representation. In this thesis a modified version
of value iteration was used for planning and it is described later in this
section. In section \ref{sec:better_planing_algos} some other methods
are presented.


\paragraph{Dynamic bayesian network structure}

Assume that the states of an MDP each are divided into several variables. For
instance, the Invasive Species MDP described in section
\ref{sec:experiment_env} constitutes such a case, where the status of each
reach can be considered a variable on its own. The number of tamarix trees,
native trees and empty slots in a certain reach at time step $t+1$ depends not
on the whole state of the environment at time $t$, but only on the status of
adjacent reaches. Those variables on which another variable depend are called
its parents.  

An MDP that follows the description in the previous paragraph is described as
factored. With the assumption of a factored MDP, it is possible to describe its
transition probabilities as a dynamic bayesian network, where one would have a
small transition probability table for each of the reaches in the MDP, instead
of a large table for the transitions for the whole states.
