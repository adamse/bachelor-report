\subsection{Optimizing bounds}

Another optimization that can be performed is that the value $\Delta \omega$ in
equation~\eqref{equation:xi} can be tweaked to fit the environment that the agent
is used with. Equation \ref{equation:xi} gives bounds for which it can be
proved that the method always converges to an optimal policy. In practice,
however, this value can be reduced by quite a bit in order to speed up the rate
at which the agent considers state-action pairs known. 

A simple linearly declining function can be used instead of
equation~\eqref{equation:xi}. In realistic implementation MBIE we have
used $\omega = 1 - \alpha N(s,a).$ The $\alpha$ parameter was decided on
through experimentation (see section \ref{sec:test_spec}).
