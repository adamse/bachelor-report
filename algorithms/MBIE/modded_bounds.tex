\subsection{Optimizing bounds \note{N}}
Another optimization that can be performed is that the value $\Delta \omega$ in equation \ref{equation:xi} can be tweaked to fit the environment that the agent is used with. Equation \ref{equation:xi} gives bounds for which it can be proved that the method always converges to an optimal policy. In practice, however, this value can be reduced by quite a bit in order to speed up the rate at which the agent considers state-action pairs known. 

A simple linearly declining function can be used instead of equation \ref{equation:xi}. In one of our implementations of MBIE we have used $\omega = 1 - \alpha N(s,a).$ The $\alpha$ parameter was decided on through experimentation (see section \ref{sec:test_spec}).