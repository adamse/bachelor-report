\section{Programming Environment \note{B}}
\label{sec:prog_env}
The Java programming language version 1.6 and 1.7 was used to implement the agents. Java is an object oriented and statically typed programming language. In addition, the java version of RL-Glue framework version 3.0 was used. For version control Git was used, due to its simplicity and performance.

\section{RL-Glue \note{N}}
\label{sec:rl_glue}
To evaluate the agents the RL-Glue framework was use, which acts as an interface for communication between the agent and the environment. The software uses the RL-Glue protocol, which specifies how a reinforcement learning problem should be divided when constructing experiments and how the different programs should communicate.

RL-Glue divides the reinforcement learning process into three separate programs: an agent, an environment and an experiment. RL-Glue provides a server software that manages the communication between these programs. The agent and the environment programs are responsible for executing the tasks as specified by RL-Glue and the experiment program acts as a bridge between the agent and environment \parencite{tanner2009rl}.
\todo[inline]{Felaktig referens va, tanner grejen?}

The modular structure of RL-Glue makes it easier to construct repeatable reinforcement learning experiments. By separating the agent from the environment it is possible to reuse the environment and switch out the agent. It also makes it a lot easier to cooperate and continue working on existing environments implemented by other programmers, possibly saving a lot of time.