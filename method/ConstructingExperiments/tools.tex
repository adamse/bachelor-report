\section{Programming environment}
\label{sec:prog_env}

The Java programming language 1.7 was used to implement the agents. In addition, the
Java version of RL-Glue framework version 3.0 was used. For version control Git
was used, due to its simplicity and performance.

\section{RL-Glue}
\label{sec:rl_glue}

To evaluate the agents the RL-Glue framework was use, which acts as an
interface for communication between the agent and the environment. The software
uses the RL-Glue protocol, which specifies how a reinforcement learning problem
should be divided when constructing experiments and how the different programs
should communicate \parencite{tanner2009rl}.

RL-Glue divides the reinforcement learning process into three separate
programs: an agent, an environment and an experiment. RL-Glue provides a server
software that manages the communication between these programs. The agent and
the environment programs are responsible for executing the tasks as specified
by RL-Glue and the experiment program acts as a bridge between the agent and
environment \parencite{tanner2009rl}.

The modular structure of RL-Glue makes it easier to construct repeatable
reinforcement learning experiments. By separating the agent from the
environment it is possible to reuse the environment and switch out the agent.
It also makes it a lot easier to cooperate and continue working on existing
environments implemented by other programmers, saving a lot of time.
