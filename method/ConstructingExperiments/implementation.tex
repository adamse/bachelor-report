\section{Algorithm implementation}
\label{sec:implementation}

In the implementations of our two algorithm we made extensions to the
algorithms as they were specified.  The experiment utilized RL-Glue
(section~\ref{sec:rl_glue}) to connect the agents and environment.  To verify
the behavior of our agents we utilized smaller environments were the correct
operation is either easy to derive or obvious from inspection. By starting with
smaller problems and using an iterative approach it was possible to identify
bottlenecks in our implementations and correct possible errors early.

\input{algorithms/MBIE/modded_bounds}

\input{method/ConstructingExperiments/contributionse3}

\subsection{GridWorld}
\label{sec:intro_grid_world}

The GridWorld environment was implemented to easily be able to verify the
correctness of the MBIE algorithm. It consists of a grid of twelve squares with
one blocked square, one starting square, one winning square, one losing square and
eight empty squares. The agent can take five actions, north, south, west,
east or exit. The exit-action is only possible from the winning or losing
state. When taking an action being in one state and the action is directed to
another empty state there is an 80\% probability to succeed and 10\%
probability to fail and 10\% to go sideways.

\subsection{Network simulator}

A simple computer network simulation was implemented to verify the behavior of an
early version of \etre\ algorithm. In this environment, the agent tries to keep
a network of computers up and running. All computers start in the running
state, but there is a chance that they randomly stop working. If a computer is
down, it has a chance to cause other computers connected to it to also fail. In
each time step, the agent chooses one computer to restart, which with 100
percent probability will be in working condition in the next time step. The
agent is rewarded for each computer in the running state after each time step. 
