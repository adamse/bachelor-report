\section{Algorithm implementation}
\label{sec:implementation}

We implemented two existing algorithms and we also added some extensions.  The
experiment utilized RL-Glue (section~\ref{sec:rl_glue}) to connect the agents
and environment to each other.  To verify the behavior of our agents we utilized smaller
environments (see sections~\ref{sec:intro_grid_world} and \ref{sec:ns}) where
the correct operation is either easy to derive or obvious from inspection. By
starting with smaller problems and using an iterative approach it was possible
to identify bottlenecks in our implementations and correct possible errors
early.

\input{algorithms/MBIE/modded_bounds}

\input{method/ConstructingExperiments/contributionse3}

\subsection{GridWorld}
\label{sec:intro_grid_world}

The GridWorld environment was implemented to easily be able to verify the
correctness of the MBIE algorithm. It consists of a grid of twelve squares with
one blocked square, one starting square, one winning square, one losing square and
eight empty squares. The agent can take five actions, north, south, west,
east or exit. The exit-action is only possible from the winning or losing
state. When taking an action being in one state and the action is directed to
another empty state there is an 80\% probability to succeed and 10\%
probability to fail and 10\% to go sideways.

\subsection{Network simulator}
\label{sec:ns}

A simple computer network simulation was implemented to verify the behavior of an
early version of \etre\ algorithm. In this environment, the agent tries to keep
a network of computers up and running. All computers start in the running
state, but there is a chance that they randomly stop working. If a computer is
down, it has a chance to cause other computers connected to it to also fail. In
each time step, the agent chooses one computer to restart, which with 100
percent probability will be in working condition in the next time step. The
agent is rewarded for each computer in the running state after each time step. 
