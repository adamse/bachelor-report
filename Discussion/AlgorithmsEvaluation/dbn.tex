\subsection{\etre\ in factored MDPs}
\label{sec:e3_factored_discussion}

In a comparison of the DBN-\etre\ agent's behavior in the different-size environments, the similarity of the shape of the graphs is striking. At first there is a period of lower and lower performance. For the smallest environments, this period is very short, however. Next, there is a period of fairly constant high performance, which lasts until the end of the experiment. This behavior is clearly visible in figures~\ref{fig:tests1}.   

The similar shapes can be explained as a consequence of the different phases  of the DBN-\etre\ algorithm and the structure of the studied MDP. In the beginning of the experiment, the algorithm will spend almost all of its time in the balanced wandering and exploration phases. The longer the agent has been exploring, and the more states become known, the further the agent has to explore into hard-to-reach parts of the MDP to find unexplored states. Now, in the case of the Invasive Species environment with the parameters chosen as in the experiments presented, the most easily reachable states are the ones where there is no tamarix infection. This means that the harder a state is to arrive at, the more infected reaches it will probably contain, and thus the performance of the DBN-\etre\ agent in the exploration phase will fall as the experiment progresses. However, once the agent knows enough about the environment to enter the exploitation phase, the DBN-\etre\ agent spends close to no time at all exploring unknown states, and it retains high performance. 


\paragraph{Possible issues with the one-policy-per-reach optimization} In section \ref{sec:one_policy_per_state_variable} an optimization is described that works very well for the particular environment and environment settings that the agent was tested for. However, this optimization makes several assumptions that may cause problems if the settings are changed. For instance, one assumption is that the state of a reach is only affected directly by its adjacent parents in river network. If the state of a reach was made to depend significantly on other reaches two or more levels up in the river network, the agent would probably not be able to converge on an optimal policy. 

Another assumption that could lead to problems with other environment settings is the assumption that the maximal action cost in the environment is impossible or very hard to break. The Invasive Species environment has a maximum cost for actions. However, with the standard settings it is mathematically impossible to break this maximum. Our implementation of DBN-\etre\ would achieve very poor performance if this was not the case, since a large penalty is given when the maximum action cost is breached. 

\paragraph{DBN structure} Finally, in the Invasive Species environment, the structure of the DBN underlying the MDP is known at the start of the experiment, so the agent does not need to infer it from observations. If this was not the case, all the DBN optimizations would be useless unless some kind of algorithm for infering the DBN structure was added to the agent. 
