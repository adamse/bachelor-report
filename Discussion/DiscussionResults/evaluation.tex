\subsection{Evaluation of experiments \note{N}}
The evaluation of the algorithms is critical for achieving good results and as well deriving conclusions regarding the results collected. Evaluating agents is a tricky process due to the process of chosing approximatly correct parameters for both the algorithm and the environment. To be more specific for example it is uncertain how much the paramaters for the MBIE affect the outcome of the experiment and trying out every diffrent combination is not possible within the scope of this thesis. However, a possible solution for this problem is to derive the optimal paramaters using mathmatical proofs.

The same problem existed when chosing the problems for the environment, Invasive Species. The obvious question is whether a different choice of paramater values would cause the DBN-\etre\ algorithm to perform in the same way or if the optimizations discussed in section \ref{sec:e3_factored_discussion} would not work in another possible setup. However, for the MBIE algorithm there is a greater probability that the results would be comparable to the results collected and discussed earlier due to the reasons given in the disussion in \ref{sec:impact_of_one_env}.

The last potential issue of the evaluation is a rather complex issue. Is the solution that the agents find really an optimal solution for the problem environment? When the number of habitats and reaches increases it becomes impossible to check manually if the policy computed by the algorithm is correct. This may be a common problem when evaluating reinforcement learning algorithms; as \textcite{dietterich2013pac} mention in their report, they too are uncertain regarding the fact that their implementation achieves an optimal solution. 