\subsection{Pre-Study \note{Ändrats lite, innehåller kommentarer}}

% Detta stycke kändes som ett bra diskussionsstycke =) Ändrade lite bara. Dock funderar jag lite kring var i raporten motiveringar till valet hör hemma. Är det här?
%In section \ref{sec:select_agents}, a number of requirements are listed of desired qualities and specifications when selecting the agents to use in the thesis. The primary specification mentioned was the fact that the the algorithm should belong to an open field and in the same time actually be able to be implemented given the scope of this thesis. An interesting aspect of the research in the area of reinforment learning is that some of the thesis in the research papers studied, lacks actual results from testing the algorithms in actual simulations. Therefore these kind of studies are more interesting to study in-depth and was  prioritized rather than an algorithm completely tested and verified. 

% There is a possibility that the algorithms studied without proper testing only works in theory due to limitations with today computers computational power and memory. Another reason behind focusing on open research topics is on the grounds that the group lacks extensive background in the RL field and have an desire to start working with practical issues rather than spending all the time in the beginning of the project reasoning about algorithms strength and weakness first handed. Instead focusing on combining the study of RL in general and bringing two selected agents to life, the learning outcome has been maximized and as the project matured the knowledge and understanding of the subject also matured making it easier to reason about the qualities of the algorithms and also find areas where optimizations can be applied. 

Because some papers do not include proper testing, it is possible that a algorithm only works in theory due to limitations with today computers computational power and memory. Another reason behind focusing on open research topics is on the grounds that the group lacks extensive background in the reinforcement learning field and have an desire to start working with practical issues rather than spending all the time in the beginning of the project reasoning about algorithms strength and weakness first handed. Instead focusing on combining the study of RL in general and bringing two selected agents to life, the learning outcome has been maximized and as the project matured the knowledge and understanding of the subject also matured making it easier to reason about the qualities of the algorithms and also find areas where optimizations can be applied. 
