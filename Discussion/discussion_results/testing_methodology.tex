\subsection{Testing methodology}

Evaluating agents is hard due to the process of choosing appropriate parameters
for both the algorithm and the environment. For example it is uncertain how
much the parameters for the algorithms affect the outcome of the experiment and
trying out all possible combination is not feasible within the scope of this
thesis. However, a possible solution for this problem is to derive the optimal
parameters using mathematical proofs.

The same problem appears when choosing the parameters for the Invasive Species
environment. The obvious question is whether a different choice of parameter values 
would cause the DBN-\etre\ algorithm to perform in the same way or if the optimizations
discussed in section \ref{sec:e3_factored_discussion} would not work in
another setting. Nevertheless, with the MBIE algorithm there is a greater
probability that the results will be comparable to the results described here. 
This is the case, as it has been tailored to the particular experiments that were performed to a lower extent
than DBN-\etre\ has.

The last potential issue of the evaluation is rather complex. Is the solution that the agents find really an optimal solution for the problem environment? When the number of habitats and reaches increases it becomes impossible to check manually if the policy computed by the algorithm is correct. This may be a common problem when evaluating reinforcement learning algorithms; as \textcite{dietterich2013pac} mention in their report, they too are uncertain regarding the fact that their implementation achieves an optimal solution. 

